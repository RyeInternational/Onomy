{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>A small hole in the side or bottom of the can ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Drill holes in your trashcans</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>James brought up the fantasy that he had read ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It just happened</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329</td>\n",
       "      <td>I have no idea what bills typically cost or th...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Trying to move out.</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359</td>\n",
       "      <td>Or may it’s just co-incidence that I’m noticin...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Slowly trying to be an adult..</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393</td>\n",
       "      <td>I guess he wanted to get revenge or something ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Not a lot of work experience, wondering how to...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>5859</td>\n",
       "      <td>Woke up way earlier than usual today.</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>Good Morning to Everyone!</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>5933</td>\n",
       "      <td>But come to find out he had drove 25 minutes t...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>College freshman wondering if my parents are b...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>5935</td>\n",
       "      <td>Long story short, I applied to do a master's d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My mom wants me to go to grad school. I don't ...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>5964</td>\n",
       "      <td>It could have the exact same features as the p...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>All penises are beautiful!!! However...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>5966</td>\n",
       "      <td>Walk back down the trail you came on your dog ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>OK so if your dog who likes to hike is a train...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           selftext  num_comments  \\\n",
       "0       218  A small hole in the side or bottom of the can ...             5   \n",
       "1        62  James brought up the fantasy that he had read ...             2   \n",
       "2       329  I have no idea what bills typically cost or th...             4   \n",
       "3       359  Or may it’s just co-incidence that I’m noticin...             0   \n",
       "4       393  I guess he wanted to get revenge or something ...             4   \n",
       "...     ...                                                ...           ...   \n",
       "1315   5859              Woke up way earlier than usual today.            11   \n",
       "1316   5933  But come to find out he had drove 25 minutes t...            17   \n",
       "1317   5935  Long story short, I applied to do a master's d...             1   \n",
       "1318   5964  It could have the exact same features as the p...            11   \n",
       "1319   5966  Walk back down the trail you came on your dog ...             0   \n",
       "\n",
       "      score                                              title   type  \n",
       "0         1                      Drill holes in your trashcans  Adult  \n",
       "1         1                                   It just happened  Adult  \n",
       "2         5                                Trying to move out.  Adult  \n",
       "3         2                     Slowly trying to be an adult..  Adult  \n",
       "4         1  Not a lot of work experience, wondering how to...  Adult  \n",
       "...     ...                                                ...    ...  \n",
       "1315      8                          Good Morning to Everyone!  Adult  \n",
       "1316      1  College freshman wondering if my parents are b...  Adult  \n",
       "1317      1  My mom wants me to go to grad school. I don't ...  Adult  \n",
       "1318      1            All penises are beautiful!!! However...  Adult  \n",
       "1319      1  OK so if your dog who likes to hike is a train...  Adult  \n",
       "\n",
       "[1320 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"NEW_Keywords_time.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_other(x):\n",
    "    x = re.sub(\"\\$\",\" \", x) #remove $\n",
    "    x = re.sub(\"https*\\S+\", \" \", x) #remove url\n",
    "    #x = re.sub(\"\\'\\w+\", '', x) #remove i'm,we're,let's after the '\n",
    "    #x = re.sub(\"[0-9]+\", '', x) #remove numbers\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatize(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    nwords=[]\n",
    "    for word in words:\n",
    "        word=lemmatizer.lemmatize(word)\n",
    "        nwords.append(word)\n",
    "    return ' '.join(nwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       A small hole in the side or bottom of the can ...\n",
       "1       James brought up the fantasy that he had read ...\n",
       "2       I have no idea what bill typically cost or the...\n",
       "3       Or may it just co-incidence that Im noticing p...\n",
       "4       I guess he wanted to get revenge or something ...\n",
       "                              ...                        \n",
       "1315                Woke up way earlier than usual today.\n",
       "1316    But come to find out he had drove 25 minute to...\n",
       "1317    Long story short, I applied to do a master's d...\n",
       "1318    It could have the exact same feature a the pic...\n",
       "1319    Walk back down the trail you came on your dog ...\n",
       "Name: selftext, Length: 1320, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext']=df['selftext'].apply(lambda x: remove_other(x))\n",
    "df['selftext']= df['selftext'].str.split().apply(lambda x: lemmatize(x))\n",
    "df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small hole in the side or bottom of the can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>James brought up the fantasy that he had read ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I have no idea what bill typically cost or the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Or may it just co-incidence that Im noticing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I guess he wanted to get revenge or something ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1315</td>\n",
       "      <td>Woke up way earlier than usual today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1316</td>\n",
       "      <td>But come to find out he had drove 25 minute to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1317</td>\n",
       "      <td>Long story short, I applied to do a master's d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>It could have the exact same feature a the pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1319</td>\n",
       "      <td>Walk back down the trail you came on your dog ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         0  A small hole in the side or bottom of the can ...\n",
       "1         1  James brought up the fantasy that he had read ...\n",
       "2         2  I have no idea what bill typically cost or the...\n",
       "3         3  Or may it just co-incidence that Im noticing p...\n",
       "4         4  I guess he wanted to get revenge or something ...\n",
       "...     ...                                                ...\n",
       "1315   1315              Woke up way earlier than usual today.\n",
       "1316   1316  But come to find out he had drove 25 minute to...\n",
       "1317   1317  Long story short, I applied to do a master's d...\n",
       "1318   1318  It could have the exact same feature a the pic...\n",
       "1319   1319  Walk back down the trail you came on your dog ...\n",
       "\n",
       "[1320 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame({'text':df['selftext']})\n",
    "X = X.dropna().reset_index()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>30</th>\n",
       "      <th>401k</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>went</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>worried</th>\n",
       "      <th>x200b</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year earlier</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 254 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000   10   15   19   20  2020  2021   30  401k  able  ...  went  wish  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...   ...   ...  ...   ...   ...  ...   ...   ...   \n",
       "1315  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "1316  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "1317  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "1318  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "1319  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0   0.0  ...   0.0   0.0   \n",
       "\n",
       "      work  working  worried  x200b      year  year ago  year earlier  years  \n",
       "0      0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "1      0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "2      0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "3      0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "4      0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "...    ...      ...      ...    ...       ...       ...           ...    ...  \n",
       "1315   0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "1316   0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "1317   0.0      0.0      0.0    0.0  0.248218       0.0           0.0    0.0  \n",
       "1318   0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "1319   0.0      0.0      0.0    0.0  0.000000       0.0           0.0    0.0  \n",
       "\n",
       "[1320 rows x 254 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#analyzer=‘char_wb’\n",
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(X['text'])\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model1.fit(count_df1)\n",
    "#model1.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def top_words(X, model, component, num_words):\n",
    "    \"\"\"\n",
    "    Extract the top words from the specified component \n",
    "    for a topic model trained on data. \n",
    "    X: a term-document matrix, assumed to be a pd.DataFrame\n",
    "    model: a sklearn model with a components_ attribute, e.g. NMF\n",
    "    component: the desired component, specified as an integer. \n",
    "        Must be less than than the total number of components in model\n",
    "    num_words: the number of words to return.\n",
    "    \"\"\"\n",
    "    orders = np.argsort(model.components_, axis = 1)\n",
    "    important_words = np.array(X.columns)[orders]\n",
    "    return important_words[component][-num_words:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tax</td>\n",
       "      <td>like im</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month</td>\n",
       "      <td>retirement</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money</td>\n",
       "      <td>age</td>\n",
       "      <td>dont time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>started</td>\n",
       "      <td>just</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>far</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>got</td>\n",
       "      <td>life</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wa</td>\n",
       "      <td>im</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earlier year</td>\n",
       "      <td>feel like</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year</td>\n",
       "      <td>feel</td>\n",
       "      <td>dont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>earlier</td>\n",
       "      <td>like</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic 0     Topic 1    Topic 2\n",
       "0           tax     like im     really\n",
       "1         month  retirement        day\n",
       "2         money         age  dont time\n",
       "3       started        just     people\n",
       "4       company         far       just\n",
       "5           got        life       work\n",
       "6            wa          im       know\n",
       "7  earlier year   feel like         wa\n",
       "8          year        feel       dont\n",
       "9       earlier        like       time"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic1=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0: tax/money/company \\\n",
    "Topic 1: retirement age/feel life \\\n",
    "Topic 2: dont have time/peole just work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=model1.fit_transform(count_df1)\n",
    "L=[]\n",
    "for i in W:\n",
    "    L.append(i.argmax())\n",
    "X['topic']=L\n",
    "t0=X[X.topic==0]\n",
    "t1=X[X.topic==1]\n",
    "t2=X[X.topic==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Emotion across topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_df(df):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "    import my_module\n",
    "    import importlib\n",
    "    importlib.reload(my_module)\n",
    "\n",
    "    #create a list of dictionaries\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "    words=[]\n",
    "\n",
    "    for line in df['text']:\n",
    "        D,pol_score=my_module.polarity_scores(sia,text=line) #use customized module\n",
    "        pol_score['text'] = line\n",
    "        results.append(pol_score)\n",
    "        words.append(D)\n",
    "    #Extract sentiment words\n",
    "    D_p=[] # positive word and its sentiment score\n",
    "    D_n=[] # negative word and its sentiment score\n",
    "    D1=[] # only positive word\n",
    "    D2=[] # only negative word\n",
    "    for i in range(len(words)):\n",
    "        newDict = {key: value for (key, value) in words[i].items() if value != 0.0 }\n",
    "        newDict1 = {key: value for (key, value) in words[i].items() if value > 0.0 }\n",
    "        newDict2 = {key: value for (key, value) in words[i].items() if value < 0.0 }\n",
    "        D_p.append(newDict1)\n",
    "        D_n.append(newDict2)\n",
    "        D1.append(list(newDict1.keys()))\n",
    "        D2.append(list(newDict2.keys()))\n",
    "    #create a df to write in the results of sentiment analysis\n",
    "    sent = pd.DataFrame(results)\n",
    "    sent['p_word_dict']=D_p\n",
    "    sent['n_word_dict']=D_n\n",
    "    p=[]\n",
    "    n=[]\n",
    "    for i in D1:\n",
    "        p.append(' '.join(i))\n",
    "    for i in D2:\n",
    "        n.append(' '.join(i))\n",
    "    sent['total']=(sent.pos-sent.neg)/sent.neu    \n",
    "    sent['p_word']=p\n",
    "    sent['n_word']=n\n",
    "    sent['label']=0\n",
    "    sent['label'].loc[sent['total']> 0]=1\n",
    "    sent['label'].loc[sent['total']< 0]=-1\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "a=sent_df(t0)\n",
    "a['topic']=0\n",
    "\n",
    "b=sent_df(t1)\n",
    "b['topic']=1\n",
    "\n",
    "c=sent_df(t2)\n",
    "c['topic']=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1320.000000\n",
       "mean        0.037098\n",
       "std         0.189573\n",
       "min        -1.197802\n",
       "25%        -0.023370\n",
       "50%         0.000000\n",
       "75%         0.115880\n",
       "max         1.865330\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=pd.concat([a,b,c],axis=0)\n",
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    622.000000\n",
       "mean       0.035259\n",
       "std        0.180575\n",
       "min       -1.197802\n",
       "25%       -0.003817\n",
       "50%        0.000000\n",
       "75%        0.115634\n",
       "max        0.949318\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Sentiment Score'), Text(0.5, 1.0, 'Sentiment Score by topics')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.boxplot(x=\"topic\", y=\"total\", data=final,showfliers = False)\n",
    "ax.set(ylabel=\"Sentiment Score\",title=\"Sentiment Score by topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common positive/negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pn(df):\n",
    "    positive=df.p_word[df['label']==1] #positive words in positive post\n",
    "    negative=df.n_word[df['label']==-1] #negative words in negative post\n",
    "    return positive,negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import collections\n",
    "def count_words(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    counts = collections.Counter(all_words)\n",
    "    counts_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ha</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pay</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>debt</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  count\n",
       "0    like    124\n",
       "1      ha     70\n",
       "2    want     47\n",
       "3    good     41\n",
       "4  credit     31\n",
       "0      no     35\n",
       "1     pay     32\n",
       "2    debt     24\n",
       "3   leave     18\n",
       "4     bad     10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(final)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ha</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>better</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pay</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>debt</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words  count\n",
       "0       ha     40\n",
       "1   better     18\n",
       "2     want     17\n",
       "3     like     17\n",
       "4   credit     16\n",
       "0       no     19\n",
       "1      pay     19\n",
       "2     debt     11\n",
       "3    leave      6\n",
       "4  anxiety      5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(a)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ha</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pay</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worried</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words  count\n",
       "0     like    100\n",
       "1     want     17\n",
       "2       ha     15\n",
       "3     good     11\n",
       "4     best     10\n",
       "0       no     10\n",
       "1      pay      7\n",
       "2  worried      7\n",
       "3     debt      7\n",
       "4     like      6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(b)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ha</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sure</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leave</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pay</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debt</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words  count\n",
       "0    good     17\n",
       "1      ha     15\n",
       "2    want     13\n",
       "3    sure     11\n",
       "4  credit     11\n",
       "0   leave      8\n",
       "1     pay      6\n",
       "2    want      6\n",
       "3      no      6\n",
       "4    debt      6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(c)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency splitted by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\") #uncomment it when run it for the first time\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "stop_words.update({'would','k','im','could','also',\n",
    "                   'amp','much','one','like','get',\n",
    "                   'since','etc','got','always',\n",
    "                   'know','thing','really','dont',\n",
    "                   'find','even','go','time','need','want'\n",
    "                  })\n",
    "def remove_stopwords(text):\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "final['text']=final['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def count_2gram(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    es2grams = ngrams(all_words, 2)\n",
    "    counts = collections.Counter(es2grams)\n",
    "    count_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "    dictionary2 = [' '.join(tup) for tup in count_df.words]\n",
    "    count_df.words=dictionary2\n",
    "\n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1320.000000\n",
       "mean        0.037098\n",
       "std         0.189573\n",
       "min        -1.197802\n",
       "25%        -0.023370\n",
       "50%         0.000000\n",
       "75%         0.115880\n",
       "max         1.865330\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           words  count\n",
       " 0         I feel     63\n",
       " 1           I wa     34\n",
       " 2   earlier year     26\n",
       " 3         feel I     17\n",
       " 4  earlier year,     14\n",
       " 5        I think     14\n",
       " 6    credit card     13\n",
       " 7   I understand     13\n",
       " 8      make sure     12\n",
       " 9     far behind     12,\n",
       "           words  count\n",
       " 0          I wa     31\n",
       " 1  earlier year     19\n",
       " 2        I feel     19\n",
       " 3     I started     11\n",
       " 4        year I      9\n",
       " 5      behind I      9\n",
       " 6       I think      8\n",
       " 7   fall behind      8\n",
       " 8     earlier I      7\n",
       " 9           I I      6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pn_freq(df):\n",
    "    count_p=count_2gram(df['text'][df['label']>0.115880]) #>0.109797 #==1\n",
    "    count_n=count_2gram(df['text'][df['label']<-0.023370]) #<-0.001208 #==-1\n",
    "    return count_p,count_n\n",
    "\n",
    "p,n=pn_freq(final)\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           words  count\n",
       " 0   earlier year     23\n",
       " 1           I wa     17\n",
       " 2  earlier year,     14\n",
       " 3   year earlier     10\n",
       " 4    credit card     10\n",
       " 5  earlier year.      9\n",
       " 6       Roth IRA      9\n",
       " 7        I think      8\n",
       " 8     earlier, I      7\n",
       " 9       two year      7,\n",
       "            words  count\n",
       " 0   earlier year     19\n",
       " 1           I wa     18\n",
       " 2      I started     11\n",
       " 3         year I      9\n",
       " 4  earlier year,      6\n",
       " 5       year ago      6\n",
       " 6      earlier I      5\n",
       " 7       I bought      5\n",
       " 8   loan earlier      5\n",
       " 9        I never      4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,n=pn_freq(final[final.topic==0])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          words  count\n",
       " 0        I feel     62\n",
       " 1        feel I     15\n",
       " 2    far behind     11\n",
       " 3   feel behind     10\n",
       " 4      feel I'm      9\n",
       " 5  I understand      8\n",
       " 6       feel Im      7\n",
       " 7      behind I      7\n",
       " 8     Im behind      6\n",
       " 9   year behind      5,\n",
       "               words  count\n",
       " 0            I feel     18\n",
       " 1              I wa      7\n",
       " 2          behind I      6\n",
       " 3        far behind      5\n",
       " 4        I'm behind      4\n",
       " 5    leaving behind      4\n",
       " 6  reasoning behind      4\n",
       " 7      I understand      4\n",
       " 8           I think      3\n",
       " 9            I plan      3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,n=pn_freq(final[final.topic==1])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           words  count\n",
       " 0           I wa     13\n",
       " 1  people behind      5\n",
       " 2        I didnt      5\n",
       " 3  reason behind      5\n",
       " 4      make sure      5\n",
       " 5         I cant      5\n",
       " 6    math behind      5\n",
       " 7    best friend      4\n",
       " 8         year I      4\n",
       " 9       behind I      4,\n",
       "          words  count\n",
       " 0         I wa      6\n",
       " 1        But I      4\n",
       " 2      I still      4\n",
       " 3      I leave      4\n",
       " 4       I fall      4\n",
       " 5  fall behind      4\n",
       " 6        I see      3\n",
       " 7     behind I      3\n",
       " 8  behind back      3\n",
       " 9     Ive seen      3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,n=pn_freq(final[final.topic==2])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling after sentiment splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1320.000000\n",
       "mean        0.037098\n",
       "std         0.189573\n",
       "min        -1.197802\n",
       "25%        -0.023370\n",
       "50%         0.000000\n",
       "75%         0.115880\n",
       "max         1.865330\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>x200b</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year earlier</th>\n",
       "      <th>year old</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000   10  100   15   19   20  2020  2021   25   30  ...      work  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "..   ...  ...  ...  ...  ...  ...   ...   ...  ...  ...  ...       ...   \n",
       "634  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.454887   \n",
       "635  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "636  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "637  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "638  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...  0.000000   \n",
       "\n",
       "      working  world  worth  x200b      year  year ago  year earlier  \\\n",
       "0    0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "1    0.000000    0.0    0.0    0.0  0.275187       0.0           0.0   \n",
       "2    0.218485    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "3    0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "4    0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "..        ...    ...    ...    ...       ...       ...           ...   \n",
       "634  0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "635  0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "636  0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "637  0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "638  0.000000    0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "\n",
       "     year old  years  \n",
       "0         0.0    0.0  \n",
       "1         0.0    0.0  \n",
       "2         0.0    0.0  \n",
       "3         0.0    0.0  \n",
       "4         0.0    0.0  \n",
       "..        ...    ...  \n",
       "634       0.0    0.0  \n",
       "635       0.0    0.0  \n",
       "636       0.0    0.0  \n",
       "637       0.0    0.0  \n",
       "638       0.0    0.0  \n",
       "\n",
       "[639 rows x 341 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(final['text'][final['label']>0.115880]) #positive\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=4, random_state=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=4,init=\"random\",random_state=1)\n",
    "model1.fit(count_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gain</td>\n",
       "      <td>late</td>\n",
       "      <td>people</td>\n",
       "      <td>going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>considering</td>\n",
       "      <td>better</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roth</td>\n",
       "      <td>left</td>\n",
       "      <td>covid</td>\n",
       "      <td>sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stock</td>\n",
       "      <td>people</td>\n",
       "      <td>told</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year earlier</td>\n",
       "      <td>help</td>\n",
       "      <td>stock</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wish</td>\n",
       "      <td>im</td>\n",
       "      <td>run</td>\n",
       "      <td>earlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tax</td>\n",
       "      <td>far</td>\n",
       "      <td>company</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earlier year</td>\n",
       "      <td>age</td>\n",
       "      <td>market</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>earlier</td>\n",
       "      <td>life</td>\n",
       "      <td>left</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>year</td>\n",
       "      <td>feel</td>\n",
       "      <td>ha</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic 0      Topic 1  Topic 2  Topic 3\n",
       "0          gain         late   people    going\n",
       "1           000  considering   better    month\n",
       "2          roth         left    covid     sure\n",
       "3         stock       people     told   credit\n",
       "4  year earlier         help    stock      job\n",
       "5          wish           im      run  earlier\n",
       "6           tax          far  company     work\n",
       "7  earlier year          age   market     make\n",
       "8       earlier         life     left    money\n",
       "9          year         feel       ha       wa"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic2=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10),\n",
    "                   'Topic 3':top_words(count_df1, model1, 3, 10)})\n",
    "topic2\n",
    "# 'Topic 4':top_words(count_df1, model1, 4, 10),\n",
    "#                     'Topic 5':top_words(count_df1, model1, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pay house/loan/car \\\n",
    "retirement \\\n",
    "credit card \\\n",
    "school friend feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>1000</th>\n",
       "      <th>12</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>2020</th>\n",
       "      <th>30</th>\n",
       "      <th>401k</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>worried</th>\n",
       "      <th>worth</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>wrong</th>\n",
       "      <th>x200b</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year earlier</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000   10  1000   12   18   19   20  2020   30  401k  ...   working  \\\n",
       "0    0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "1    0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "2    0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "3    0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "4    0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "..   ...  ...   ...  ...  ...  ...  ...   ...  ...   ...  ...       ...   \n",
       "362  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "363  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.361371   \n",
       "364  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "365  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "366  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.000000   \n",
       "\n",
       "     worried  worth  wouldnt  wrong  x200b      year  year ago  year earlier  \\\n",
       "0        0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "1        0.0    0.0      0.0    0.0    0.0  0.635503       0.0           0.0   \n",
       "2        0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "3        0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "4        0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "..       ...    ...      ...    ...    ...       ...       ...           ...   \n",
       "362      0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "363      0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "364      0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "365      0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "366      0.0    0.0      0.0    0.0    0.0  0.000000       0.0           0.0   \n",
       "\n",
       "     years  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "362    0.0  \n",
       "363    0.0  \n",
       "364    0.0  \n",
       "365    0.0  \n",
       "366    0.0  \n",
       "\n",
       "[367 rows x 309 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(final['text'][final['label']<-0.023370]) #negative\n",
    "counts=counts.toarray()\n",
    "count_df2=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=4, random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=NMF(n_components=4,init=\"random\",random_state=0)\n",
    "model2.fit(count_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month</td>\n",
       "      <td>make</td>\n",
       "      <td>started</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phone</td>\n",
       "      <td>fall</td>\n",
       "      <td>job earlier</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lot</td>\n",
       "      <td>way</td>\n",
       "      <td>loan</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said</td>\n",
       "      <td>saving</td>\n",
       "      <td>work</td>\n",
       "      <td>leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>started</td>\n",
       "      <td>getting</td>\n",
       "      <td>debt</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wall</td>\n",
       "      <td>work</td>\n",
       "      <td>job</td>\n",
       "      <td>far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>insurance</td>\n",
       "      <td>retirement</td>\n",
       "      <td>pay</td>\n",
       "      <td>debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>company</td>\n",
       "      <td>car</td>\n",
       "      <td>earlier year</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>told</td>\n",
       "      <td>money</td>\n",
       "      <td>earlier</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wa</td>\n",
       "      <td>im</td>\n",
       "      <td>year</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic 0     Topic 1       Topic 2    Topic 3\n",
       "0      month        make       started       help\n",
       "1      phone        fall   job earlier        bad\n",
       "2        lot         way          loan    thought\n",
       "3       said      saving          work      leave\n",
       "4    started     getting          debt     little\n",
       "5       wall        work           job        far\n",
       "6  insurance  retirement           pay       debt\n",
       "7    company         car  earlier year  financial\n",
       "8       told       money       earlier       life\n",
       "9         wa          im          year       feel"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic3=pd.DataFrame({'Topic 0':top_words(count_df2, model2, 0, 10),\n",
    "                   'Topic 1':top_words(count_df2, model2, 1, 10),\n",
    "                   'Topic 2':top_words(count_df2, model2, 2, 10),\n",
    "                   'Topic 3':top_words(count_df2, model2, 3, 10)})\n",
    "topic3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live home/parent \\\n",
    "credit card and insurance \\\n",
    "retirement \\\n",
    "parent talking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all adj. related to parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download('punkt')\n",
    "sentence=df['selftext'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parent(sentence_ele):\n",
    "    L=[]\n",
    "    for i in sentence_ele:\n",
    "        if 'time' in i: \n",
    "            L.append(i)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_sentence=sentence.apply(lambda x: extract_parent(x))\n",
    "' '.join(parent_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-eea6f49be0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tokens=nltk.word_tokenize(parent_sentence[39][1])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d3ab67a198cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "def extract_adj(sentence_ele):\n",
    "    adjs=[]\n",
    "    for i in sentence_ele:\n",
    "        tokens=nltk.word_tokenize(i)\n",
    "        df_type=pd.DataFrame(nltk.pos_tag(tokens),columns=['words', 'type'])\n",
    "        adjs=list(df_type[df_type.type=='JJ'].words)\n",
    "    return ' '.join(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs=parent_sentence.apply(lambda x: extract_adj(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \n",
       "1        \n",
       "2        \n",
       "3        \n",
       "4        \n",
       "       ..\n",
       "1315     \n",
       "1316     \n",
       "1317     \n",
       "1318     \n",
       "1319     \n",
       "Name: selftext, Length: 1320, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-64232679c296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcount_df1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \"\"\"\n\u001b[1;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 raise ValueError(\n\u001b[1;32m   1214\u001b[0m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0;32m-> 1215\u001b[0;31m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m   1089\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(max_df=0.5,min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(adjs)\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=0)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model1.fit(count_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>hard</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>current</td>\n",
       "      <td>great</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great</td>\n",
       "      <td>current</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>possible</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>monthly</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sure</td>\n",
       "      <td>long</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>little</td>\n",
       "      <td>financial</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>financial</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>sure</td>\n",
       "      <td>monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good</td>\n",
       "      <td>new</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic 0    Topic 1    Topic 2\n",
       "0      small       hard      great\n",
       "1    current      great    current\n",
       "2      great    current       hard\n",
       "3       free   possible       free\n",
       "4       high    monthly  financial\n",
       "5       sure       long       long\n",
       "6     little  financial       live\n",
       "7  financial     little     little\n",
       "8       able       sure    monthly\n",
       "9       good        new        old"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic1=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>’</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>own</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>able</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>old</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>much</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>few</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>first</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>financial</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>due</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sure</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>next</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>little</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>*</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  count\n",
       "0           ’    347\n",
       "1         own    188\n",
       "2        good    155\n",
       "3       other    154\n",
       "4         new    143\n",
       "5        able    138\n",
       "6         old    137\n",
       "7        much    126\n",
       "8         few    126\n",
       "9           m    122\n",
       "10      first    122\n",
       "11  financial    119\n",
       "12          i    105\n",
       "13       last    103\n",
       "14        due    103\n",
       "15       sure     96\n",
       "16       next     93\n",
       "17     little     83\n",
       "18          *     82\n",
       "19       high     75"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all words across rows\n",
    "import itertools\n",
    "import collections\n",
    "def count_words(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    counts = collections.Counter(all_words)\n",
    "    counts_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "    return counts_df\n",
    "count_words(adjs).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>able</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>financial</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>last</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>due</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sure</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>next</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words  count\n",
       "0       good    155\n",
       "1        new    143\n",
       "2       able    138\n",
       "3        old    137\n",
       "4      first    122\n",
       "5  financial    119\n",
       "6       last    103\n",
       "7        due    103\n",
       "8       sure     96\n",
       "9       next     93"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words.update({'i','*','im','’','much'})\n",
    "adjs=adjs.apply(lambda x: remove_stopwords(x))\n",
    "count_df=count_words(adjs)\n",
    "count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
